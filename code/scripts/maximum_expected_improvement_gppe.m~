function mei = maximum_expected_improvement_gppe(covfunc_t, covfunc_x, theta, f, Kx, ...
    Kinv, W, L, t, x, idx_global, ind_t, ind_x, tstar, idx_xstar, fbest)
%  mei = maximum_expected_improvement_gppe(covfunc_t, covfunc_x, theta, f, Kx, ...
%    Kinv, W, L, t, x, idx_global, ind_t, ind_x, tstar, idx_xstar, fbest)

% Computes the maximum expected improvement (MEI) of recommending items
% given by indices idx_xstar on user with features tstar
%
% idx_xstar: indices of all the possible items I wish to consider
% Adding the case of a new item is straightforward as I just need to use
% the new features xstar and compute the kernel kx using covfunc_x


% Edwin V. Bonilla (edwin.bonilla@nicta.com.au)
% Last update: 22/05/2012

covfunc_t = check_covariance(covfunc_t);
covfunc_x = check_covariance(covfunc_x);

[theta_t, theta_x, theta_sigma] = get_gppe_parameters(covfunc_t, covfunc_x, theta, t, x);
clear theta;
sigma = exp(theta_sigma);


%% here we compute the expected utilities (and variances) of all items!
[Kt_ss, Kt_star] = feval(covfunc_t{:}, theta_t, t, tstar);
Kx_star = Kx(idx_xstar,:)';                 % test to training
Kx_star_star = Kx(idx_xstar, idx_xstar);    % test to test

kstar = kron(Kt_star, Kx_star);
kstar = kstar(idx_global,:);
Kss = Kt_ss * Kx_star_star;


mustar = kstar'*Kinv*f(idx_global);
Css    = Kss - kstar'*W*solve_chol(L',Kinv*kstar);  % Kss - Kstar'*(K + W^{-1} )^{-1} * kstar
varstar = diag(Css); % I dont need covariances, may consider to do things more efficiently


%%
sigmastar = sqrt(varstar);
z = (fbest - mustar)./sigmastar;
pdfval = normpdf(z);
cdfval = normcdf(z);
el = sigmastar .* ( z.*(1-cdfval) - pdfval );



mei = max( - el);


%figure;plot_confidence_interval(idx_xstar, mustar , sigmastar, 1);

